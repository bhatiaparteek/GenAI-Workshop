{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8AZ+5TUslYXrhSHGEFW7t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhatiaparteek/GenAI-Workshop/blob/main/GenAI_for_Application_Development_Workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ================================================================\n",
        "# GenAI for Application Development Workshop\n",
        "# ================================================================\n",
        "# üß† Basic OpenAI API Demos:\n",
        "# 1Ô∏è‚É£ Prompting and Text Completion\n",
        "# 2Ô∏è‚É£ Translation and Summarization\n",
        "# 3Ô∏è‚É£ Creative Text Generation\n",
        "# 4Ô∏è‚É£ Email / Resume Polishing Assistant\n",
        "# 5Ô∏è‚É£ Sentiment Analysis\n",
        "# 6Ô∏è‚É£ Code Explanation and Debugging\n",
        "# 7Ô∏è‚É£ Building a Simple Interface\n",
        "# ================================================================\n"
      ],
      "metadata": {
        "id": "XhQcCbRMOVky"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "yynOF26uOLAA"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# 1Ô∏è‚É£ Install the OpenAI SDK\n",
        "!pip install --quiet openai\n",
        "\n",
        "# 2Ô∏è‚É£ Import libraries\n",
        "from openai import OpenAI\n",
        "import getpass\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3Ô∏è‚É£ Enter your OpenAI API key\n",
        "# You can get it from https://platform.openai.com/api-keys\n",
        "api_key = getpass.getpass(\"Enter your OpenAI API key: \")\n",
        "client = OpenAI(api_key=api_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhtgmhf1ObMp",
        "outputId": "3c88cedf-72d0-40b5-f361-7dd686db07bd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ---------------------------------------------------------------\n",
        "# BASIC PROMPT COMPLETION\n",
        "# ---------------------------------------------------------------"
      ],
      "metadata": {
        "id": "eKOKM1_uSY90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------\n",
        "# BASIC PROMPT COMPLETION\n",
        "# ---------------------------------------------------------------\n",
        "def basic_prompt(prompt_text):\n",
        "    \"\"\"\n",
        "    Function: basic_prompt()\n",
        "\n",
        "    Purpose:\n",
        "        Generates a simple text completion (response) using OpenAI's GPT model.\n",
        "        This is the most fundamental demonstration of how to send a user prompt\n",
        "        to a large language model and retrieve its response.\n",
        "\n",
        "    Parameters:\n",
        "        prompt_text (str): The user's question, instruction, or input text.\n",
        "                          Example: \"Explain Generative AI in simple terms.\"\n",
        "\n",
        "    Process:\n",
        "        1. Sends the user's text to the model using the Chat Completions API.\n",
        "        2. Waits for the model to process and return a natural language reply.\n",
        "        3. Prints the response neatly in the notebook output.\n",
        "\n",
        "    Notes:\n",
        "        ‚Ä¢ Uses the \"gpt-4o-mini\" model ‚Äî optimized for speed and cost.\n",
        "        ‚Ä¢ You can experiment by changing the model (e.g., \"gpt-4o\").\n",
        "        ‚Ä¢ Ideal for exploring prompt design, tone, and context sensitivity.\n",
        "\n",
        "    Example Usage:\n",
        "        >>> basic_prompt(\"Explain Generative AI in simple terms.\")\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Create a chat completion request with user's input\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",  # Fast, cost-efficient model for demo\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt_text}]\n",
        "        )\n",
        "\n",
        "        # Print the model's generated response\n",
        "        print(\" Response:\\n\")\n",
        "        print(response.choices[0].message.content.strip())\n",
        "\n",
        "    except Exception as e:\n",
        "        # Catch and display any error (e.g., network, API key, rate limit)\n",
        "        print(\" Error:\", e)\n",
        "\n",
        "\n",
        "#  Example Run\n",
        "basic_prompt(\"Explain Generative AI in simple terms.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y356TLFxPCyO",
        "outputId": "037cc17c-9851-414e-85b4-e2c8becdc507"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Response:\n",
            "\n",
            "Generative AI is a type of artificial intelligence that can create new content, such as text, images, music, or even videos, based on the information it has learned. It works by analyzing a lot of existing examples and then using that knowledge to generate something original.\n",
            "\n",
            "Think of it like a very smart artist or writer: instead of copying what‚Äôs already out there, it uses what it knows to produce something new and unique. For example, if you give it a prompt like \"a cat in a space suit,\" generative AI can come up with a picture or story that matches that idea, even if it hasn't seen that exact combination before. \n",
            "\n",
            "In short, generative AI is all about creating new things using learned patterns from previous data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ---------------------------------------------------------------\n",
        "# TRANSLATION\n",
        "# ---------------------------------------------------------------"
      ],
      "metadata": {
        "id": "N56QqTV602gx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------\n",
        "# TRANSLATION\n",
        "# ---------------------------------------------------------------\n",
        "def translate_text(text, target_language):\n",
        "    \"\"\"Translate text into the target language.\"\"\"\n",
        "    try:\n",
        "        prompt = f\"Translate the following text into {target_language}:\\n\\n{text}\"\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "        print(f\"\\n Translation ({target_language}):\\n\")\n",
        "        print(response.choices[0].message.content.strip())\n",
        "    except Exception as e:\n",
        "        print(\"‚ùå Error:\", e)\n",
        "\n",
        "# Example:\n",
        "translate_text(\"Generative AI is transforming how we create content.\", \"French\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vo1oUKObPMXu",
        "outputId": "5a9253bf-40d6-491a-f567-bad3ed2f5218"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Translation (French):\n",
            "\n",
            "L'IA g√©n√©rative transforme notre mani√®re de cr√©er du contenu.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ---------------------------------------------------------------\n",
        "# SUMMARIZATION\n",
        "# ---------------------------------------------------------------"
      ],
      "metadata": {
        "id": "rZ7ug_ky05Y5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------\n",
        "# SUMMARIZATION\n",
        "# ---------------------------------------------------------------\n",
        "def summarize_text(text):\n",
        "    \"\"\"Summarize long text into concise sentences.\"\"\"\n",
        "    try:\n",
        "        prompt = f\"Summarize the following text in 2-3 sentences:\\n\\n{text}\"\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "        print(\"\\n Summary:\\n\")\n",
        "        print(response.choices[0].message.content.strip())\n",
        "    except Exception as e:\n",
        "        print(\" Error:\", e)\n",
        "\n",
        "# Example:\n",
        "sample_text = \"\"\"\n",
        "Generative AI models such as GPT can create coherent and creative text,\n",
        "images, and even code from minimal input. They learn from large datasets,\n",
        "enabling automation, creativity, and productivity across various industries.\n",
        "\"\"\"\n",
        "summarize_text(sample_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVLD5y4VPmUn",
        "outputId": "7c61fe19-83cd-4caa-fa72-aa307dd80290"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Summary:\n",
            "\n",
            "Generative AI models like GPT can produce coherent text, images, and code with minimal input by learning from extensive datasets. This technology enhances automation, creativity, and productivity across multiple industries.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ---------------------------------------------------------------\n",
        "# CREATIVE TEXT GENERATION\n",
        "# ---------------------------------------------------------------"
      ],
      "metadata": {
        "id": "U5lonc_y09vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------\n",
        "# CREATIVE TEXT GENERATION\n",
        "# ---------------------------------------------------------------\n",
        "def creative_text(topic, style=\"poem\", tone=\"inspirational\"):\n",
        "    \"\"\"\n",
        "    Generates creative content (story, poem, tagline) for a given topic.\n",
        "\n",
        "    Parameters:\n",
        "      topic (str): Subject or theme to write about.\n",
        "      style (str): 'poem', 'story', 'tagline', etc.\n",
        "      tone (str): Tone of writing such as 'funny', 'inspirational', 'formal'.\n",
        "\n",
        "    Example:\n",
        "      creative_text(\"Artificial Intelligence\", \"story\", \"inspirational\")\n",
        "    \"\"\"\n",
        "    try:\n",
        "        prompt = f\"Write a short {tone} {style} about {topic}.\"\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "        print(f\" {style.capitalize()} about '{topic}':\\n\")\n",
        "        print(response.choices[0].message.content.strip())\n",
        "    except Exception as e:\n",
        "        print(\" Error:\", e)\n",
        "\n",
        "\n",
        "# Example Run\n",
        "creative_text(\"Generative AI\", \"poem\", \"inspirational\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kw6y6MerQC8m",
        "outputId": "ae85c704-b17b-4dde-9679-668d4dcb0ab8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Poem about 'Generative AI':\n",
            "\n",
            "In circuits bright where thoughts take flight,  \n",
            "A spark of code ignites the night,  \n",
            "With every line, new worlds unfold,  \n",
            "A canvas rich, as dreams are told.  \n",
            "\n",
            "Whispers of hope through algorithms stream,  \n",
            "Crafting the fabric of a shared dream,  \n",
            "From art to words, creation's embrace,  \n",
            "Generative hearts in a boundless space.  \n",
            "\n",
            "Together we learn, together we grow,  \n",
            "In the dance of data, possibilities flow,  \n",
            "With each new query, with each bold guess,  \n",
            "Generative AI‚Äîa spark to impress.  \n",
            "\n",
            "So harness the wisdom, let visions arise,  \n",
            "In this wondrous journey, the future complies,  \n",
            "Side by side, the human and the machine,  \n",
            "In harmony crafting what once might have been.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ---------------------------------------------------------------\n",
        "# EMAIL / RESUME POLISHING ASSISTANT\n",
        "# ---------------------------------------------------------------"
      ],
      "metadata": {
        "id": "hyAbuQ0g1DOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------\n",
        "# EMAIL / RESUME POLISHING ASSISTANT\n",
        "# ---------------------------------------------------------------\n",
        "def polish_email(raw_text):\n",
        "    \"\"\"\n",
        "    Refines a rough email into a professional, concise version.\n",
        "\n",
        "    Parameters:\n",
        "      raw_text (str): The informal or draft email content.\n",
        "\n",
        "    Example:\n",
        "      polish_email(\"hi i want to apply for this job pls find resume attached\")\n",
        "    \"\"\"\n",
        "    try:\n",
        "        prompt = f\"Polish the following email to make it professional and polite:\\n\\n{raw_text}\"\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "        print(\" Polished Email:\\n\")\n",
        "        print(response.choices[0].message.content.strip())\n",
        "    except Exception as e:\n",
        "        print(\" Error:\", e)\n",
        "\n",
        "\n",
        "# Example Run\n",
        "polish_email(\"hi i want to apply for this job pls find resume attached\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJe2oTK7QP1a",
        "outputId": "5e3766b5-0173-4938-e38a-3ae1327d07fe"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Polished Email:\n",
            "\n",
            "Subject: Job Application\n",
            "\n",
            "Dear [Recipient's Name],\n",
            "\n",
            "I hope this message finds you well.\n",
            "\n",
            "I am writing to express my interest in the [job title] position listed at [Company Name]. Please find my resume attached for your consideration.\n",
            "\n",
            "Thank you for your time. I look forward to the opportunity to discuss my application further.\n",
            "\n",
            "Best regards,\n",
            "\n",
            "[Your Name]  \n",
            "[Your Contact Information]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ---------------------------------------------------------------\n",
        "# SENTIMENT ANALYSIS\n",
        "# ---------------------------------------------------------------"
      ],
      "metadata": {
        "id": "9H5H7jIo1IZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------\n",
        "# SENTIMENT ANALYSIS\n",
        "# ---------------------------------------------------------------\n",
        "def analyze_sentiment(text):\n",
        "    \"\"\"\n",
        "    Performs zero-shot sentiment analysis on text (Positive / Negative / Neutral).\n",
        "\n",
        "    Parameters:\n",
        "      text (str): Input text to analyze.\n",
        "\n",
        "    Example:\n",
        "      analyze_sentiment(\"I love how easy this API is to use!\")\n",
        "    \"\"\"\n",
        "    try:\n",
        "        prompt = f\"Classify the sentiment of this text as Positive, Negative, or Neutral:\\n\\n{text}\"\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "        print(\" Sentiment:\\n\")\n",
        "        print(response.choices[0].message.content.strip())\n",
        "    except Exception as e:\n",
        "        print(\" Error:\", e)\n",
        "\n",
        "\n",
        "# Example Run\n",
        "analyze_sentiment(\"The workshop was informative but a bit too long.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QYXAPJwQZC2",
        "outputId": "43be77e1-bc71-48f0-a07d-38d31c0440ae"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Sentiment:\n",
            "\n",
            "The sentiment of the text can be classified as Neutral. While it mentions that the workshop was informative (a positive aspect), it also expresses a negative sentiment about its length, leading to an overall neutral tone.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ---------------------------------------------------------------\n",
        "# CODE EXPLANATION / DEBUGGING\n",
        "# ---------------------------------------------------------------"
      ],
      "metadata": {
        "id": "lfpO8D_P1NE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------\n",
        "# CODE EXPLANATION / DEBUGGING\n",
        "# ---------------------------------------------------------------\n",
        "def explain_code(code_snippet):\n",
        "    \"\"\"\n",
        "    Explains what a given Python code snippet does in plain English.\n",
        "\n",
        "    Parameters:\n",
        "      code_snippet (str): The Python code to analyze.\n",
        "\n",
        "    Example:\n",
        "      explain_code('for i in range(5): print(i**2)')\n",
        "    \"\"\"\n",
        "    try:\n",
        "        prompt = f\"Explain what the following Python code does in simple terms:\\n\\n{code_snippet}\"\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "        print(\" Code Explanation:\\n\")\n",
        "        print(response.choices[0].message.content.strip())\n",
        "    except Exception as e:\n",
        "        print(\" Error:\", e)\n",
        "\n",
        "\n",
        "# Example Run\n",
        "explain_code(\"numbers = [1,2,3,4]; print([n**2 for n in numbers if n%2==0])\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDRGh_c-QhKm",
        "outputId": "44141702-afa2-4d95-d221-54e34e9b9bb9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Code Explanation:\n",
            "\n",
            "The given Python code does the following:\n",
            "\n",
            "1. **Create a List of Numbers:** It starts by defining a list called `numbers` that contains the integers 1, 2, 3, and 4.\n",
            "\n",
            "2. **List Comprehension:** It uses a list comprehension to create a new list. A list comprehension is a concise way to generate lists in Python. \n",
            "\n",
            "3. **Filtering Even Numbers:** Inside the list comprehension:\n",
            "   - `for n in numbers` means it will go through each number `n` in the `numbers` list.\n",
            "   - `if n % 2 == 0` is a condition that checks if `n` is even. This means it only picks `n` if it can be divided by 2 without a remainder.\n",
            "\n",
            "4. **Squaring the Even Numbers:** For each even number that meets the condition, `n**2` is calculated. This is the square of the number (e.g., for 2, it would compute \\(2^2 = 4\\)).\n",
            "\n",
            "5. **Print the Result:** Finally, it prints the new list that contains the squares of the even numbers from the original list.\n",
            "\n",
            "So, when you run this code, it will identify the even numbers from the list (`2` and `4`), square them (resulting in `4` and `16`), and print the list `[4, 16]`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------------------------------------------\n",
        "BUILDING INTERFACE\n",
        "---------------------------------------------------------------"
      ],
      "metadata": {
        "id": "xdbcnRs71Uol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "pX-fBPXKQ94y"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------\n",
        "# DEFINE ALL FUNCTIONS\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "def run_genai(task, text, lang1=\"English\", lang2=\"French\", style=\"poem\", tone=\"inspirational\"):\n",
        "    \"\"\"\n",
        "    Unified function for multiple GenAI tasks.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if task == \"Basic Prompt\":\n",
        "            prompt = text\n",
        "\n",
        "        elif task == \"Summarization\":\n",
        "            prompt = f\"Summarize the following text in 2-3 concise sentences:\\n\\n{text}\"\n",
        "\n",
        "        elif task == \"Translation\":\n",
        "            prompt = f\"Translate the following text from {lang1} to {lang2}:\\n\\n{text}\"\n",
        "\n",
        "        elif task == \"Email Polisher\":\n",
        "            prompt = f\"Polish the following email to make it professional and polite:\\n\\n{text}\"\n",
        "\n",
        "        elif task == \"Code Explanation\":\n",
        "            prompt = f\"Explain what the following Python code does in simple terms:\\n\\n{text}\"\n",
        "\n",
        "        elif task == \"Sentiment Analysis\":\n",
        "            prompt = f\"Classify the sentiment of this text as Positive, Negative, or Neutral:\\n\\n{text}\"\n",
        "\n",
        "        elif task == \"Creative Text\":\n",
        "            prompt = f\"Write a short {tone} {style} about {text}.\"\n",
        "\n",
        "        else:\n",
        "            return \" Invalid task selected.\"\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\" Error: {e}\"\n"
      ],
      "metadata": {
        "id": "YOCbo3FhRDg-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------\n",
        "# GRADIO INTERFACE\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "with gr.Blocks(title=\"GenAI for Application Development\") as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # üöÄ GenAI for Application Development\n",
        "    Explore how to use OpenAI models for everyday tasks ‚Äî text generation, summarization, translation, and more.\n",
        "    **Developed for: Workshop on Generative AI Applications**\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        task = gr.Dropdown(\n",
        "            [\"Basic Prompt\", \"Summarization\", \"Translation\", \"Email Polisher\",\n",
        "             \"Code Explanation\", \"Sentiment Analysis\", \"Creative Text\"],\n",
        "            label=\"Select Task\",\n",
        "            value=\"Basic Prompt\"\n",
        "        )\n",
        "\n",
        "    text = gr.Textbox(label=\"Enter your text, prompt, or code here\", lines=6)\n",
        "\n",
        "    with gr.Row(visible=False) as translation_opts:\n",
        "        lang1 = gr.Textbox(label=\"From Language\", value=\"English\")\n",
        "        lang2 = gr.Textbox(label=\"To Language\", value=\"French\")\n",
        "\n",
        "    with gr.Row(visible=False) as creative_opts:\n",
        "        style = gr.Dropdown([\"poem\", \"story\", \"tagline\"], label=\"Creative Style\", value=\"poem\")\n",
        "        tone = gr.Dropdown([\"inspirational\", \"humorous\", \"formal\"], label=\"Tone\", value=\"inspirational\")\n",
        "\n",
        "    output = gr.Textbox(label=\"üßæ Output\", lines=8)\n",
        "\n",
        "    # Dynamic visibility for special fields\n",
        "    def toggle_fields(task):\n",
        "        return (\n",
        "            gr.update(visible=(task == \"Translation\")),\n",
        "            gr.update(visible=(task == \"Creative Text\"))\n",
        "        )\n",
        "\n",
        "    task.change(fn=toggle_fields, inputs=task, outputs=[translation_opts, creative_opts])\n",
        "\n",
        "    run_btn = gr.Button(\"‚ñ∂Ô∏è Run\")\n",
        "    run_btn.click(fn=run_genai,\n",
        "                  inputs=[task, text, lang1, lang2, style, tone],\n",
        "                  outputs=output)\n",
        "\n",
        "    gr.Markdown(\" *Tip:* Try switching between tasks and editing your text to see how responses vary.\")\n"
      ],
      "metadata": {
        "id": "hyPQmjZ5RLO5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------\n",
        "# üöÄ LAUNCH APP\n",
        "# ---------------------------------------------------------------\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "ATPnJLcuRNeo",
        "outputId": "e0d3f690-0be8-4159-d35d-44ee016ecd7b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://762f1938939f7eb043.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://762f1938939f7eb043.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment: Build Your Own GenAI Task"
      ],
      "metadata": {
        "id": "XY1DK08DvNbl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Xos6UFRvTJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "New Task: Social Media Content Generator\n",
        "Use GenAI to create platform-specific, engaging, and audience-appropriate content. **bold text**\n"
      ],
      "metadata": {
        "id": "HWgxngtsv11v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hints:\n",
        "elif task == \"Social Media Content Generator\":\n",
        "    prompt = (\n",
        "        f\"Create a short, engaging social media post for {style} platform \"\n",
        "        f\"based on the following idea or announcement:\\n\\n{text}\\n\\n\"\n",
        "        f\"Use a {tone} tone and include relevant emojis or hashtags if suitable.\"\n",
        "    )\n",
        "\n",
        "print(run_genai(\n",
        "    task=\"Social Media Content Generator\",\n",
        "    text=\"We‚Äôre hosting a hands-on workshop on Agentic AI this weekend at WSU!\",\n",
        "    style=\"LinkedIn\",\n",
        "    tone=\"enthusiastic\"\n",
        "))"
      ],
      "metadata": {
        "id": "BGaHkCM9y8iY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------\n",
        "# STUDENT ACTIVITY: SOCIAL MEDIA POST GENERATOR (Half-Cooked)\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "def social_media_post(idea, platform, tone):\n",
        "    \"\"\"\n",
        "    TODO: Complete this function to generate a short, engaging post\n",
        "    based on the given idea, platform, and tone.\n",
        "\n",
        "    Parameters:\n",
        "      idea (str): The message or announcement you want to post.\n",
        "      platform (str): Platform name (LinkedIn, Instagram, Twitter/X, etc.)\n",
        "      tone (str): Tone of writing (professional, friendly, motivational, etc.)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Step 1: Create a custom prompt\n",
        "        # üëâ HINT: Include platform and tone context.\n",
        "\n",
        "\n",
        "        # Step 2: Use the OpenAI API to get completion\n",
        "        # üëâ HINT: Use client.chat.completions.create()\n",
        "        # response = ...\n",
        "\n",
        "        )\n",
        "\n",
        "        # Step 3: Extract and print the response\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"‚ö†Ô∏è Error:\", e)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# üß™ TEST YOUR FUNCTION BELOW\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "# Try editing the parameters to observe tone and style differences\n",
        "social_media_post(\n",
        "    idea=\"Join us for the hands-on Agentic AI Workshop this weekend at UCSD!\",\n",
        "    platform=\"LinkedIn\",\n",
        "    tone=\"enthusiastic\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "XgapqN3B0HT_",
        "outputId": "909eadcb-cf21-416e-ed0e-75e9374378d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unmatched ')' (ipython-input-202991090.py, line 24)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-202991090.py\"\u001b[0;36m, line \u001b[0;32m24\u001b[0m\n\u001b[0;31m    )\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
          ]
        }
      ]
    }
  ]
}